{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Info:\n",
    "The Project Title is: The Epidemiology of COVID-19\n",
    "\n",
    "Group member 1 \n",
    "name: Austin Hickey\n",
    "e-mail: U1041943@utah.edu\n",
    "UID: U1041943\n",
    "\n",
    "Group member 2\n",
    "name: Spencer Sawas\n",
    "e-mail: spencer.sawas@utah.edu\n",
    "UID: U1065866\n",
    "\n",
    "Group member 3\n",
    "name: Marko Miholjcic\n",
    "e-mail: u0984549@utah.edu\n",
    "UID: u0984549"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background and Motivation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the world is facing a global pandemic with a new virus that has evolved and crossed over to humans. The virus known as COVID-19 affects the respiratory and cardiovascular systems by binding to the Ace-2 receptors. Ace-2 receptors are found throughout the cardiovascular and respiratory system. For this reason, the virus is extremely dangerous for susceptible populations. Currently, 30% of Americans suffer from cardiovascular diseases, 10% from diabetes, and 10% from asthma; these populations do not account for those who are immunocompromised or more susceptible for other reasons. \n",
    "The virus causes violent coughing, restricted breathing, inflammation, and cardiovascular hypertension (among other cardiovascular effects). Furthermore, it can cause pneumonia. Pneumonia can be fatal; especially if left untreated. \n",
    "Due to how transmissible the virus is, hospitals and healthcare workers across the world have been put to the test. The rapid spread of the virus has caused many hospitals to become overloaded with patients, with limited resources available. \n",
    "\n",
    "To try and curb the spread of the virus, countries across the world are temporarily shutting down and government officials have been recommended to social quarentine. Ripple effects have been detrimental to the economy. Millions of people have lost their jobs. People are dipping into their savings to pay rent, while others are unable to pay rent. Some economists have speculated an economic recession after the virus passes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Objectives ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understand the severity of the global pandemic and predict the effects to come in the near future for states in the United States and countries around the world. Using predictive modeling techniques such as logistic regression, we will identify how long until the number of cases begins to plateau, how many cases there will be when it begins to plateau, and a prediction of the number of deaths a location will experience. \n",
    "\n",
    "We will use the predictive models to create plots to visualize the severity of the virus in the locations analyzed. Further, we will explore which states will be most heavily impacted. A geospatial map will be created to plot the spread of COVID-19 in the United States and identify the hospital beds per 1,000 for each state.\n",
    "\n",
    "The benefits? \n",
    "What would you like to learn and accomplish?\n",
    "\n",
    "These variables will provide an oppurtunity to perform a clustering analysis to determine if they are any realtionships between variables and the cases in a state. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using several sources of data in order to accurately represent the COVID-19 outbreaks and information relevant to analyzing contributing factors to the outbreak.\n",
    "\n",
    "For the COVID-19 data we will use multiple APIs of a github repository to collect the number of cases, recoveries, and deaths over time for a number of countries and all of the US states. \n",
    "This data is a collection of data put together in csv format by John Hopkins Center for Systems Science and Engineering. Data extracted will be between the dates of January 22, 2020 and April 1, 2020. The github webpage is:\n",
    "https://github.com/CSSEGISandData/COVID-19.\n",
    "\n",
    "Below a single url is retrieved and placed into a dataframe in order to display the data that is imported from the API. Each day, the github repository updates the cumulative number of cases, recoveries, and deaths. The data also provides the province/state and country/region where the cases are occuring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-22-2020.csv'\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(url)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our regression model to predict the number of deaths from COVID-19 that a particular country will experience we will be extracting data from the WHO Healthcare index pdf. A countries healthcare index is a good indicator of how adept their healthcare infrastructure is, and how healthy a country is overall. The WHO healthcare index takes into account myriad of variables to rank every nations healthcare system.\n",
    "https://www.who.int/healthinfo/paper30.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "with pdfplumber.open(r\"C:\\Users\\austi\\Documents\\GitHub\\COMP5360Project\\project_files\\pdf_resources\\world_health_index.pdf\") as pdf:\n",
    "    pages = pdf.pages[17]\n",
    "    table = pages.extract_table()\n",
    "    pages2 = pdf.pages[18]\n",
    "    table2 = pages2.extract_table()\n",
    "    pages3 = pdf.pages[19]\n",
    "    table3 = pages3.extract_table()\n",
    "    pages4 = pdf.pages[20]\n",
    "    table4 = pages4.extract_table()\n",
    "    \n",
    "df = pd.DataFrame(table[1:], columns=table[1])\n",
    "df.head()\n",
    "df=df[['Rank','Member State', 'Index']]\n",
    "\n",
    "data = pd.DataFrame(table2[1:], columns=table2[1])\n",
    "data=data[['55','Albania', '0.774']]\n",
    "data=data.rename(columns={'55':'Rank','Albania':'Member State', '0.774':'Index'})                \n",
    "df=df.append(data,ignore_index=True)\n",
    "\n",
    "data = pd.DataFrame(table3[1:], columns=table3[1])\n",
    "data=data[['117','Uzbekistan', '0.599']]\n",
    "data=data.rename(columns={'117':'Rank','Uzbekistan':'Member State', '0.599':'Index'})                 \n",
    "df=df.append(data,ignore_index=True)\n",
    "\n",
    "data = pd.DataFrame(table4[1:], columns=table4[1])\n",
    "data=data[['178','Chad', '0.303']]\n",
    "data=data.rename(columns={'178':'Rank','Chad':'Member State', '0.303':'Index'})                  \n",
    "df=df.append(data,ignore_index=True)\n",
    "\n",
    "for column in [\"Rank\", \"Member State\", 'Index']:\n",
    "    df[column] = df[column].str.replace(\" \", \"\")\n",
    "    df[column] = df[column].replace('\\n','', regex=True)\n",
    "df=df.dropna()\n",
    "df=df.drop([0])\n",
    "df.set_index('Rank')\n",
    "df['Rank']=df['Rank'].astype(int)\n",
    "df['Index']=df['Index'].astype(float)\n",
    "df['Member State']=df['Member State'].astype(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(df)\n",
    "    \n",
    "df.to_csv(r'C:\\Users\\austi\\Documents\\GitHub\\COMP5360Project\\project_files\\csv_files\\CLEAN_WorldHealthIndex.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The population and population densities are collected from an csv file downloaded from the following website: http://worldpopulationreview.com/. We gathered two csv files from the website. One csv file had data from the states while the other csv file had data for all of the countries in the world. ******* States needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/csv_files/population_and_density_by_country.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, on a national level we will consider additional variables such as state populations/density and the size of the existing healthcare systems for each state (number of hospital beds per 1,000 people). The following website was utilized: https://www.kff.org/other/state-indicator/beds-by-ownership/?currentTimeframe=0&selectedDistributions=statelocal-government&sortModel=%7B%22colId%22:%22Location%22,%22sort%22:%22asc%22%7D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.kff.org/other/state-indicator/beds-by-ownership/?currentTimeframe=0&selectedDistributions=statelocal-government&print=true&sortModel=%7B%22colId%22:%22State%2FLocal%20Government%22,%22sort%22:%22asc%22%7D'\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/pdf_resources/HospitalBed.txt\", \"w\")\n",
    "file.write(response.text)\n",
    "file = open(\"/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/pdf_resources/HospitalBed.txt\", \"r\")\n",
    "content = file.readlines()\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, we will use data gathered from each country in the United States. This excel file will provide us with a plethora of variables to exlpore, such as the number of physicians per county for each state. The link to the website where the excel document was downloaded from is: https://www.countyhealthrankings.org/explore-health-rankings/rankings-data-documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\austi\\Documents\\GitHub\\COMP5360Project\\project_files\\csv_files\\2020 County Health Rankings Data - v1.csv',skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethical considerations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this were published, and publicly visible; we would not want our project to induce mass hysteria for the states that have been identified to be most severely impacted. It would also be important that our project does not identify a state that is least impacted- and influence them to go against governmental restrictions that were put in place.\n",
    "\n",
    "As we are working with an ongoing crisis we are using the data while also upholding the real concequences this data is having on hundreds of thousands of lives in America and across the world. Our use of this data is not meant to be insensitive but instead to try and highlight exactly how extreme this can become. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data processing will be done within jupyter notebook running python software. The API, CSV, and data obtained from web scraping will all need to be loaded into a jupyter notebook and will converted from JSON, dictionary, and/or lists into a pandas data frame for processing and analysis.\n",
    "The github repository had multiple formats for date and the abbreviations of locations where cases had occured. Therefore, most APIs had their format altered in order to create consistency dates and locations of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "dates = ['01-22', '01-23', '01-24', '01-25', '01-26', '01-27', '01-28', '01-29', '01-30', '01-31']\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for x in range(len(dates)):\n",
    "    url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/' + dates[x] + '-2020.csv'\n",
    "    response = requests.get(str(url))\n",
    "        \n",
    "    df1 = pd.read_csv(url)\n",
    "    df1['Last Update'] = df1['Last Update'].apply(lambda x : \"0\" + x[0:7] + \"20\")\n",
    "    states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\", \"Delaware\",\n",
    "          \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\",\n",
    "          \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \n",
    "          \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \n",
    "          \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \n",
    "          \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \n",
    "          \"West Virginia\", \"Wisconsin\", \"Wyoming\", \"District of Columbia\"]\n",
    "    abb = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \n",
    "       \"LA\", \"ME\", \"MD\", \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \"NM\", \"NY\", \"NC\", \"ND\", \"OH\",\n",
    "       \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\", \"DC\"]\n",
    "\n",
    "    for x in range(51):\n",
    "        df1[\"Province/State\"] = df1[\"Province/State\"].replace(states[x], abb[x])\n",
    "    \n",
    "        df1[\"Province/State\"] = df1[\"Province/State\"].replace(\"Chicago\", \"IL\")    \n",
    "    df = df.append(df1, ignore_index = True)\n",
    "\n",
    "#df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-01-2020.csv'\n",
    "response = requests.get(url)\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : \"0\" + x[0:1] + \"/0\" + x[2:6] + \"20\")\n",
    "mask = df1['Last Update'] == \"02/01/2020\"\n",
    "df1 = df1.loc[mask]\n",
    "\n",
    "df1[\"Province/State\"] = df1[\"Province/State\"].fillna(\"none\") \n",
    "df1['Province/State'] = df1['Province/State'].apply(lambda x : x[-2:])\n",
    "df = df.append(df1, ignore_index = True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates2 = ['02-02', '02-03', '02-04', '02-05', '02-06', '02-07', '02-08', '02-09', '02-10', '02-11', '02-12',\n",
    "        '02-13', '02-14', '02-15', '02-16', '02-17', '02-18', '02-19', '02-20', '02-21', '02-22', '02-23',\n",
    "        '02-24', '02-25', '02-26', '02-27', '02-28', '02-29']\n",
    "\n",
    "for x in range(len(dates2)):\n",
    "    url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/' + dates2[x] + '-2020.csv'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    df1 = pd.read_csv(url)\n",
    "    df1['Last Update'] = df1['Last Update'].apply(lambda x : \"0\" + x[6:10] + \"/\" + \"2020\")\n",
    "    df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "    mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "    df1 = df1.loc[mask]\n",
    "\n",
    "    df1[\"Province/State\"] = df1[\"Province/State\"].replace(\"Omaha, NE (From Diamond Princess)\", \"NE\")\n",
    "    df1[\"Province/State\"] = df1[\"Province/State\"].replace(\"Travis, CA (From Diamond Princess)\", \"CA\")\n",
    "    df1[\"Province/State\"] = df1[\"Province/State\"].replace(\"Lackland, TX (From Diamond Princess)\", \"TX\")\n",
    "\n",
    "    df1[\"Province/State\"] = df1[\"Province/State\"].fillna(\"none\") \n",
    "    df1['Province/State'] = df1['Province/State'].apply(lambda x : x[-2:])\n",
    "\n",
    "    df = df.append(df1, ignore_index = True)\n",
    "\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates3 = ['03-01', '03-02', '03-03', '03-04', '03-05', '03-06', '03-07', '03-08', '03-09']\n",
    "\n",
    "for x in range(len(dates3)):\n",
    "    url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/' + dates3[x] + '-2020.csv'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    df1 = pd.read_csv(url)\n",
    "    df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "    df1['Last Update'] = df1['Last Update'].apply(lambda x : \"0\" + x[6:7] + \"/0\" + x[9] + \"/\" + \"2020\")\n",
    "    df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "    mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "    df1 = df1.loc[mask]\n",
    "\n",
    "    df1[\"Province/State\"] = df1[\"Province/State\"].replace(\"Omaha, NE (From Diamond Princess)\", \"NE\")\n",
    "    df1[\"Province/State\"] = df1[\"Province/State\"].replace(\"Travis, CA (From Diamond Princess)\", \"CA\")\n",
    "    df1[\"Province/State\"] = df1[\"Province/State\"].replace(\"Lackland, TX (From Diamond Princess)\", \"TX\")\n",
    "    df1[\"Province/State\"] = df1[\"Province/State\"].replace(\"Washington, D.C.\", \"DC\")\n",
    "\n",
    "    df1[\"Province/State\"] = df1[\"Province/State\"].fillna(\"none\") \n",
    "    df1['Province/State'] = df1['Province/State'].apply(lambda x : x[-2:])\n",
    "\n",
    "    df = df.append(df1, ignore_index = True)\n",
    "    \n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates4 = ['03-10', '03-11', '03-12', '03-13', '03-14', '03-15', '03-16', '03-17', \n",
    "        '03-18', '03-19', '03-20', '03-21']\n",
    "\n",
    "for x in range(len(dates4)):\n",
    "    url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/' + dates4[x] + '-2020.csv'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    df1 = pd.read_csv(url)\n",
    "    df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "    df1['Last Update'] = df1['Last Update'].apply(lambda x : \"0\" + x[6:10] + \"/\" + \"2020\")\n",
    "    df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "    mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "    df1 = df1.loc[mask]\n",
    "    states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\", \"Delaware\",\n",
    "          \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\",\n",
    "          \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \n",
    "          \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \n",
    "          \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \n",
    "          \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \n",
    "          \"West Virginia\", \"Wisconsin\", \"Wyoming\", \"District of Columbia\"]\n",
    "    abb = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \n",
    "       \"LA\", \"ME\", \"MD\", \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \"NM\", \"NY\", \"NC\", \"ND\", \"OH\",\n",
    "       \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\", \"DC\"]\n",
    "\n",
    "    for x in range(51):\n",
    "        df1[\"Province/State\"] = df1[\"Province/State\"].replace(states[x], abb[x])\n",
    "    \n",
    "    df = df.append(df1, ignore_index = True)\n",
    "    \n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-22-2020.csv'\n",
    "response = requests.get(url)\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1.rename(columns={\"Province_State\": \"Province/State\", \"Country_Region\": \"Country/Region\", \"Last_Update\": \"Last Update\"})\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x :\"0\" + x[0:7] + \"20\")\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "\n",
    "states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\", \"Delaware\",\n",
    "          \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\",\n",
    "          \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \n",
    "          \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \n",
    "          \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \n",
    "          \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \n",
    "          \"West Virginia\", \"Wisconsin\", \"Wyoming\", \"District of Columbia\"]\n",
    "abb = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \n",
    "       \"LA\", \"ME\", \"MD\", \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \"NM\", \"NY\", \"NC\", \"ND\", \"OH\",\n",
    "       \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\", \"DC\"]\n",
    "\n",
    "for x in range(51):\n",
    "    df1[\"Province/State\"] = df1[\"Province/State\"].replace(states[x], abb[x])\n",
    "\n",
    "df = df.append(df1, ignore_index = True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates5 = ['03-23', '03-24', '03-25', '03-26', '03-27', '03-28', \n",
    "        '03-29', '03-30', '03-31', '04-01']\n",
    "\n",
    "for x in range(len(dates5)):\n",
    "    url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/' + dates5[x] + '-2020.csv'\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    df1 = pd.read_csv(url)\n",
    "    df1 = df1.rename(columns={\"Province_State\": \"Province/State\", \"Country_Region\": \"Country/Region\", \"Last_Update\": \"Last Update\"})\n",
    "    df1 = df1[[\"Province/State\", \"Country/Region\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "\n",
    "    df1['Last Update'] = df1['Last Update'].apply(lambda x : \"0\" + x[6:10] + \"/2020\")\n",
    "    df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "    mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "    df1 = df1.loc[mask]\n",
    "    states = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\", \"Delaware\",\n",
    "          \"Florida\", \"Georgia\", \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\", \"Kansas\", \"Kentucky\", \"Louisiana\",\n",
    "          \"Maine\", \"Maryland\", \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\", \"Montana\", \n",
    "          \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"New York\", \"North Carolina\", \n",
    "          \"North Dakota\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\", \n",
    "          \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\", \"Virginia\", \"Washington\", \n",
    "          \"West Virginia\", \"Wisconsin\", \"Wyoming\", \"District of Columbia\"]\n",
    "    abb = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \n",
    "       \"LA\", \"ME\", \"MD\", \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \"NM\", \"NY\", \"NC\", \"ND\", \"OH\",\n",
    "       \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\", \"DC\"]\n",
    "\n",
    "    for x in range(51):\n",
    "        df1[\"Province/State\"] = df1[\"Province/State\"].replace(states[x], abb[x])\n",
    "\n",
    "    df = df.append(df1, ignore_index = True)\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/csv_files/CDRdata.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After saving the dataframe with all of the countries, the following lines of code, selected the desired countries and US states for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/csv_files/CDRdata.csv\")\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/spenc/OneDrive/Documents/University_of_Utah/2019-2020/DataScience/COMP5360Project/project_files/csv_files/CDRdata.csv\")\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\austi\\Documents\\GitHub\\COMP5360Project\\project_files\\csv_files\\CDRdata.csv\")\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"Confirmed\"] = df[\"Confirmed\"].fillna(0)\n",
    "df[\"Deaths\"] = df[\"Deaths\"].fillna(0)\n",
    "df[\"Recovered\"] = df[\"Recovered\"].fillna(0)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"Country/Region\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Country/Region\"] = df[\"Country/Region\"].replace(\"Mainland China\", \"China\")\n",
    "df[\"Country/Region\"] = df[\"Country/Region\"].replace(\"Korea, South\", \"South Korea\")\n",
    "df[\"Country/Region\"] = df[\"Country/Region\"].replace(\"UK\", \"United Kingdom\")\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "countries = ['US', 'China', 'Italy', 'New Zealand', 'South Korea', 'United Kingdom', 'Iran', 'Australia', 'India', 'Peru']\n",
    "df = df.loc[df['Country/Region'].isin(countries)]\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Confirmed\"] = df[\"Confirmed\"].astype(\"int\")\n",
    "df[\"Deaths\"] = df[\"Deaths\"].astype(\"int\")\n",
    "df[\"Recovered\"] = df[\"Recovered\"].astype(\"int\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/Users/spenc/OneDrive/Documents/University_of_Utah/2019-2020/DataScience/COMP5360Project/project_files/csv_files/CLEANCDRData.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/csv_files/CLEANCDRData.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\austi\\Documents\\GitHub\\COMP5360Project\\project_files\\csv_files\\CLEANCDRData.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/csv_files/CDRdata.csv\")\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Confirmed\"] = df[\"Confirmed\"].fillna(0)\n",
    "df[\"Deaths\"] = df[\"Deaths\"].fillna(0)\n",
    "df[\"Recovered\"] = df[\"Recovered\"].fillna(0)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[df[\"Country/Region\"] == \"US\"]\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abb = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \n",
    "       \"LA\", \"ME\", \"MD\", \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \"NM\", \"NY\", \"NC\", \"ND\", \"OH\",\n",
    "       \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\", \"DC\"]\n",
    "\n",
    "dataUS = data[data[\"Province/State\"].isin(abb)]\n",
    "dataUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataUS.to_csv('/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/csv_files/usaCLEANCDRData.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data had to be extracted from the pdf for each country.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "with pdfplumber.open(r\"C:\\Users\\austi\\Documents\\GitHub\\COMP5360Project\\project_files\\pdf_resources\\world_health_index.pdf\") as pdf:\n",
    "    pages = pdf.pages[17]\n",
    "    table = pages.extract_table()\n",
    "    pages2 = pdf.pages[18]\n",
    "    table2 = pages2.extract_table()\n",
    "    pages3 = pdf.pages[19]\n",
    "    table3 = pages3.extract_table()\n",
    "    pages4 = pdf.pages[20]\n",
    "    table4 = pages4.extract_table()\n",
    "    \n",
    "df = pd.DataFrame(table[1:], columns=table[1])\n",
    "df.head()\n",
    "df=df[['Rank','Member State', 'Index']]\n",
    "\n",
    "data = pd.DataFrame(table2[1:], columns=table2[1])\n",
    "data=data[['55','Albania', '0.774']]\n",
    "data=data.rename(columns={'55':'Rank','Albania':'Member State', '0.774':'Index'})                \n",
    "df=df.append(data,ignore_index=True)\n",
    "\n",
    "data = pd.DataFrame(table3[1:], columns=table3[1])\n",
    "data=data[['117','Uzbekistan', '0.599']]\n",
    "data=data.rename(columns={'117':'Rank','Uzbekistan':'Member State', '0.599':'Index'})                 \n",
    "df=df.append(data,ignore_index=True)\n",
    "\n",
    "data = pd.DataFrame(table4[1:], columns=table4[1])\n",
    "data=data[['178','Chad', '0.303']]\n",
    "data=data.rename(columns={'178':'Rank','Chad':'Member State', '0.303':'Index'})                  \n",
    "df=df.append(data,ignore_index=True)\n",
    "\n",
    "for column in [\"Rank\", \"Member State\", 'Index']:\n",
    "    df[column] = df[column].str.replace(\" \", \"\")\n",
    "    df[column] = df[column].replace('\\n','', regex=True)\n",
    "df=df.dropna()\n",
    "df=df.drop([0])\n",
    "df.set_index('Rank')\n",
    "df['Rank']=df['Rank'].astype(int)\n",
    "df['Index']=df['Index'].astype(float)\n",
    "df['Member State']=df['Member State'].astype(str)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The countries included in the report were selected from the population data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/csv_files/population_and_density_by_country.csv\")\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/spenc/OneDrive/Documents/University_of_Utah/2019-2020/DataScience/COMP5360Project/project_files/csv_files/population_and_density_by_country.csv\")\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df[[\"name\",\"Rank\", \"pop2019\", \"GrowthRate\", \"area\", \"Density\"]]\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "countries = ['China','United States', 'Italy', 'New Zealand', 'South Korea', 'United Kingdom', 'Iran', 'Singapore', 'India', 'Peru']\n",
    "df = df.loc[df['name'].isin(countries)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pop2019'] = df['pop2019'].astype('int')\n",
    "df['area'] = df['area'].astype('int')\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/csv_files/CLEANpopulation_and_density_by_country.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***** STATE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this we will focus in on a select number of countries to focus the data frame and the data relating to the number of outbreaks and the number of deaths.\n",
    "Latitude and longitude data for the outbreaks in the United States will be utilized to create visual geospatial plot of the outbreaks in the US for the predicted and actual number of cases.\n",
    "Upon cleaning the data the formatting of the date and province/date columns had to be modifyed as the 'date' and 'province' strings were in different formats from the GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

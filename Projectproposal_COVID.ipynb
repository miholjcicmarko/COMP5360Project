{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Info:\n",
    "The Project Title is: The Epidemiology of COVID-19\n",
    "\n",
    "Group member 1 \n",
    "name: Austin Hickey\n",
    "e-mail: U1041943@utah.edu\n",
    "UID: U1041943\n",
    "\n",
    "Group member 2\n",
    "name: Spencer Sawas\n",
    "e-mail: spencer.sawas@utah.edu\n",
    "UID: U1065866\n",
    "\n",
    "Group member 3\n",
    "name: Marko Miholjcic\n",
    "e-mail: u0984549@utah.edu\n",
    "UID: u0984549"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background and Motivation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently the world is facing a global pandemic with a new virus that has evolved and crossed over to humans. The virus known as COVID-19 affects the respiratory and cardiovascular systems by binding to the Ace-2 receptors. Ace-2 receptors are found widespread through the cardiovascular and respiratory system, for this reason the virus is extremely dangerous for susceptible populations. Currently, 30% of Americans suffer from cardiovascular diseases, 10% diabetus, and 10% asthma; these populations dont even account for those who are immunocompromised or more susceptible for other reasons. \n",
    "The virus causes violent coughing, restricted breathing, inflammation, and cardiovascular hypertension (among other cardiovascular effects). Further, it can cause pneumonia. Combined with the complications caused by the virus, pneumonia is can be fatal; especially if left untreated. \n",
    "Due to how transmissible the virus is, hospitals and healthcare workers across the world have been put to the test. The rapid spread of the virus has caused many hospitals to become overloaded with patients, with limited resources available. \n",
    "\n",
    "To try and curb the spread of the virus, places across the world are temporarily shutting down and countries have been recommended to social quarentine, or have gone into a full lockdown. Ripple effects have been detrimental to the economy. Millions of people have lost their jobs. People are dipping into their savings to pay rent, or worse, they can't pay rent. Some have even speculated an economic recession after the virus passes. \n",
    "\n",
    "This virus shows just how ill equipt the United States and the entire world are for pandemics and biological warfare that may present itself in the future. Hopefully this can be a learning experience for every nation, if nothing else. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understand the severity of the global pandemic and visualize the effects to come in the near future when it's at its worst in the United States. Using predictive modeling techniques such as logistic regression and classification models, we will identify how long until the number of cases begins to plateau, how many cases there will be when it begins to plateau, and a prediction of the number of deaths a location will experience. \n",
    "\n",
    "We will use the predictive models to create plots to visualize the severity of the virus in the locations analyzed. Further, we will explore which states will be most heavily impacted. A geospatial map will be created to plot the spread of COVID-19 in the United States and identify the hospital beds per 1,000 for each state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using several sources of data in order to most accurately represent the COVID-19 outbreaks and information relevant to analyzing its effects on each country.\n",
    "\n",
    "For the COVID-19 data we will use multiple APIs to collect the number of cases, recoveries, and deaths over time (since Jan.) for a number of countries: \n",
    "This data is collection of data put together in csv format by John Hopkins Center for Systems Science and Engineering.\n",
    "https://github.com/CSSEGISandData/COVID-19 \n",
    "\n",
    "For our regression model to predict the number of deaths from COVID-19 that a particular country will experience we will be webscraping data from the WHO Healthcare index. A countries healthcare index is a good indicator of how adept their healthcare infrastructure is, and how healthy a country is overall. The WHO healthcare index takes into account myriad of variables to rank every nations healthcare system.\n",
    "https://www.who.int/healthinfo/paper30.pdf (pdf example)\n",
    "As well as a particular countries population and population densities - http://worldpopulationreview.com/\n",
    "\n",
    "Lastly, on a national level we will consider additional variables such as state populations/density and the size of the existing healthcare systems for each state (number of hospital beds per 1,000 people). Further, we will use data that identifies the number of physicians per county for each state. These variables will provide for a more robust classification model to predict the severity of impact the virus will have on every state. \n",
    "https://www.kff.org/other/state-indicator/beds-by-ownership/?currentTimeframe=0&selectedDistributions=statelocal-government&sortModel=%7B%22colId%22:%22Location%22,%22sort%22:%22asc%22%7D\n",
    "\n",
    "https://www.countyhealthrankings.org/explore-health-rankings/rankings-data-documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethical considerations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this were published, and publicly visible; we would not want our project to induce mass hysteria for the states that have been identified to be most severely impacted. It would also be important that our project does not identify a state that is least impacted- and influence them to go against governmental restrictions that were put in place.\n",
    "\n",
    "As we are working with an ongoing crisis we are using the data while also upholding the real concequences this data is having on hundreds of thousands of lives in America and across the world. Our use of this data is not meant to be insensitive but instead to try and highlight exactly how extreme this can become. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data processing will be done within jupyter notebook running python software. The API, CSV, and data obtained from web scraping will all need to be loaded into a jupyter notebook and will converted from JSON, dictionary, and/or lists into a pandas data frame for processing and analysis.\n",
    "\n",
    "With this we will focus in on a select number of countries to focus the data frame and the data relating to the number of outbreaks and the number of deaths. \n",
    "\n",
    "Latitude and longitude data for the outbreaks in the United States will be utilized to create visual geospatial plot of the outbreaks in the US for the predicted and actual number of cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the world-wide data used in creating our linear regression we will use a few different methods to check for strong correlations for independent variables that can most accurately predict the number of deaths observed in a region. We will use heat maps in combination with a correlation matrix to observe the strongest correlation and determine which parameters to utlize within the regressional analysis. \n",
    "\n",
    "Similary when aiming to predict exactly how severe the outbreaks in each of the United States will become after creating a base model that produces a theorectical curve we will need to check its accuracy. We will do an anlaysis of the residuals to compare the theorectical data to the existing outbreak data to find the standard error of the mean to determine its accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As breifly stated above we will be trying to create a regression model that is able to predict how manh deaths will be observed in a country based on determined parameters. This will be done using in part built in python packages such as ols. The existing data for each country (which dates back to January) will be utilized for the prediction for the select countries and can be checked by comparing to the published existing data in those regions, as well as further validated by comparing the models predictions to the data in countries not used for the thorough analysis.\n",
    "\n",
    "For the state data, we are aiming to model the progression of the pandemic in each of the states. To do this, we will utilize exisitng growth models for populations of animals. We will test multiple models and utilize curve fitting toolkits such as scipy to determine any unknown constants from the existing number of cases data. These existing models include logistic, Bertalanffy, or the Gompertz. We will then analyze the residues as states above to determine the standard error of the mean in combination with determining the R-squared value to choose the most accurate model for COVID-19 in the United States. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Schedule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 1:\n",
    "    -the data must be imported into the jupyter notebook.\n",
    "    -Begin cleaning the data \n",
    "    -Participate in peer review\n",
    "\n",
    "Week 2:\n",
    "    -Spring Break\n",
    "   \n",
    "\n",
    "Week 3:\n",
    "    -Finish cleaning the data\n",
    "    -Begin exploring the data\n",
    "\n",
    "\n",
    "Week 4:\n",
    "    -Finish Exploring the Data\n",
    "    -Begin Analyzing the Data\n",
    "    -Determine the method of creating the video\n",
    "\n",
    "Week 5:\n",
    "    -Complete the analysis of the Data\n",
    "    -Begin creating the video\n",
    "\n",
    "Week 6:\n",
    "    -Finalize the jupyter notebook\n",
    "    -Finish the video \n",
    "\n",
    "Week 7:\n",
    "    -Practice the presentation\n",
    "\n",
    "Week 8:\n",
    "    -Present the presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## John's Hopkins COVID-19 DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-22-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(response.content)\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "df\n",
    "\n",
    "df['Last Update'] = df['Last Update'].apply(lambda x : x[0:7])\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-23-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[0:7])\n",
    "df1\n",
    "\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-24-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[0:7])\n",
    "df1\n",
    "\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-25-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[0:7])\n",
    "df1\n",
    "\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-26-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[0:7])\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-27-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[0:7])\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-28-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[0:7])\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-29-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[0:7])\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-30-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[0:7])\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/01-31-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[0:7])\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "Changes time format. Adjust the string modifying\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-01-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[0:6])\n",
    "mask = df1['Last Update'] == \"2/1/20\"\n",
    "df1 = df1.loc[mask]\n",
    "\n",
    "df1\n",
    "\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "Time Format Changes again. Adjust string modification. \n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-02-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:7] + \"/\" + x[9] + \"/\" + \"20\")\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-03-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:7] + \"/\" + x[9] + \"/\" + \"20\")\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-04-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:7] + \"/\" + x[9] + \"/\" + \"20\")\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-05-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:7] + \"/\" + x[9] + \"/\" + \"20\")\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-06-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:7] + \"/\" + x[9] + \"/\" + \"20\")\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-07-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:7] + \"/\" + x[9] + \"/\" + \"20\")\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-08-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:7] + \"/\" + x[9] + \"/\" + \"20\")\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-09-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:7] + \"/\" + x[9] + \"/\" + \"20\")\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "Date Format Changes.\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-10-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-11-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-12-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-13-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-14-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-15-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-16-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-17-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-18-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-19-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-20-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-21-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-22-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-23-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-24-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-25-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-26-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-27-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-28-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/02-29-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "Change in date format. \n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-01-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:7] + \"/\" + x[9] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-02-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:7] + \"/\" + x[9] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-03-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:7] + \"/\" + x[9] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-04-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:7] + \"/\" + x[9] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-05-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:7] + \"/\" + x[9] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-06-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:7] + \"/\" + x[9] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-07-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:7] + \"/\" + x[9] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-08-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:7] + \"/\" + x[9] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-09-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:7] + \"/\" + x[9] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "Change in Date Format\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-10-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-11-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-12-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-13-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-14-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-15-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-16-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-17-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-18-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-19-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-20-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-21-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\",  \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/\" + \"20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "Changes Formats for time. \n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-22-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1.rename(columns={\"Province_State\": \"Province/State\", \"Country_Region\": \"Country/Region\", \"Last_Update\": \"Last Update\"})\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[0:7])\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "Format Changes\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-23-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1.rename(columns={\"Province_State\": \"Province/State\", \"Country_Region\": \"Country/Region\", \"Last_Update\": \"Last Update\"})\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-24-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1.rename(columns={\"Province_State\": \"Province/State\", \"Country_Region\": \"Country/Region\", \"Last_Update\": \"Last Update\"})\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-25-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1.rename(columns={\"Province_State\": \"Province/State\", \"Country_Region\": \"Country/Region\", \"Last_Update\": \"Last Update\"})\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-26-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1.rename(columns={\"Province_State\": \"Province/State\", \"Country_Region\": \"Country/Region\", \"Last_Update\": \"Last Update\"})\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-27-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1.rename(columns={\"Province_State\": \"Province/State\", \"Country_Region\": \"Country/Region\", \"Last_Update\": \"Last Update\"})\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-28-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1.rename(columns={\"Province_State\": \"Province/State\", \"Country_Region\": \"Country/Region\", \"Last_Update\": \"Last Update\"})\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x[6:10] + \"/20\")\n",
    "df1['Last Update'] = df1['Last Update'].apply(lambda x : x.replace(\"-\", \"/\"))\n",
    "mask = df1['Last Update'] == df1['Last Update'][0]\n",
    "df1 = df1.loc[mask]\n",
    "df1\n",
    "\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "df.to_csv('CDRdata.csv', index = False)\n",
    "\n",
    "The beginning of the LatLon Code. Need to Switch the Date possibly. \n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-01-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-02-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-03-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-04-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-05-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-06-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-07-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-08-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-09-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-10-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-11-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-12-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-13-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-14-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-15-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-16-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-17-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-18-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-19-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-20-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-21-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-22-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1.rename(columns={\"Province_State\": \"Province/State\", \"Country_Region\": \"Country/Region\", \"Last_Update\": \"Last Update\", \"Lat\":\"Latitude\", \"Long_\":\"Longitude\"})\n",
    "df1\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\", \"Latitude\", \"Longitude\"]]\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-23-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1.rename(columns={\"Province_State\": \"Province/State\", \"Country_Region\": \"Country/Region\", \"Last_Update\": \"Last Update\", \"Lat\":\"Latitude\", \"Long_\":\"Longitude\"})\n",
    "df1\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\", \"Latitude\", \"Longitude\"]]\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-24-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1.rename(columns={\"Province_State\": \"Province/State\", \"Country_Region\": \"Country/Region\", \"Last_Update\": \"Last Update\", \"Lat\":\"Latitude\", \"Long_\":\"Longitude\"})\n",
    "df1\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\", \"Latitude\", \"Longitude\"]]\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-25-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1.rename(columns={\"Province_State\": \"Province/State\", \"Country_Region\": \"Country/Region\", \"Last_Update\": \"Last Update\", \"Lat\":\"Latitude\", \"Long_\":\"Longitude\"})\n",
    "df1\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\", \"Latitude\", \"Longitude\"]]\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-26-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1.rename(columns={\"Province_State\": \"Province/State\", \"Country_Region\": \"Country/Region\", \"Last_Update\": \"Last Update\", \"Lat\":\"Latitude\", \"Long_\":\"Longitude\"})\n",
    "df1\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\", \"Latitude\", \"Longitude\"]]\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/03-27-2020.csv'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "df1 = pd.read_csv(url)\n",
    "df1 = df1.rename(columns={\"Province_State\": \"Province/State\", \"Country_Region\": \"Country/Region\", \"Last_Update\": \"Last Update\", \"Lat\":\"Latitude\", \"Long_\":\"Longitude\"})\n",
    "df1\n",
    "df1 = df1[[\"Province/State\", \"Country/Region\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\", \"Latitude\", \"Longitude\"]]\n",
    "df = df.append(df1, ignore_index = True)\n",
    "df\n",
    "\n",
    "df.to_csv('LatLongdata.csv', index = False)\n",
    "\n",
    "latlon = pd.read_csv('LatLongdata.csv')\n",
    "latlon\n",
    "\n",
    "mask = latlon[\"Country/Region\"] == \"US\"\n",
    "df = latlon.loc[mask]\n",
    "df\n",
    "\n",
    "#df.to_csv('USLatLon.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Hospital Beds per 1000 people in the United States: Scraping A Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "website = pd.read_html('https://www.kff.org/other/state-indicator/beds-by-ownership/?currentTimeframe=0&selectedDistributions=statelocal-government&sortModel=%7B%22colId%22:%22Location%22,%22sort%22:%22asc%22%7D')\n",
    "https://www.kff.org/other/state-indicator/beds-by-ownership/?currentTimeframe=0&selectedDistributions=statelocal-government&sortModel=%7B%22colId%22%3A%22Location%22%2C%22sort%22%3A%22asc%22%7D\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.kff.org/other/state-indicator/beds-by-ownership/?currentTimeframe=0&selectedDistributions=statelocal-government&print=true&sortModel=%7B%22colId%22:%22State%2FLocal%20Government%22,%22sort%22:%22asc%22%7D'\n",
    "response = requests.get(url)\n",
    "response\n",
    "\n",
    "file = open(\"HospitalBed.txt\", \"w\")\n",
    "file.write(response.text)\n",
    "file = open(\"HospitalBed.txt\", \"r\")\n",
    "content = file.readlines()\n",
    "content\n",
    "\n",
    "BigSoup = BeautifulSoup()\n",
    "\n",
    "soup = BeautifulSoup(open(\"HospitalBed.txt\"), \"html.parser\")\n",
    "BigSoup.append(soup)\n",
    "\n",
    "print(BigSoup.prettify())\n",
    "\n",
    "littlesoup = BigSoup.find(id = \"content\")\n",
    "ls = str(littlesoup)\n",
    "print(ls)\n",
    "\n",
    "indexS = ls.find('[\"Alabama\"')\n",
    "indexE = ls.find(']],[\"2017\"')\n",
    "\n",
    "data_s = ls[indexS:indexE]\n",
    "\n",
    "\n",
    "print(data_s)\n",
    "\n",
    "data_s = \"[\" + data_s + \"]\"\n",
    "data_s\n",
    "\n",
    "import ast\n",
    "data = ast.literal_eval(data_s)\n",
    "\n",
    "data\n",
    "\n",
    "columns = [\"Location\",\"State\\Local Government\",\"Non-Profit\",\"For-Profit\", \"Total\"]\n",
    "\n",
    "df = pd.DataFrame(data, columns = columns)\n",
    "df\n",
    "\n",
    "df = df[[\"Location\", \"Total\"]]\n",
    "df\n",
    "\n",
    "df.to_csv(r'/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/csv_files/Hospitals.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Importing National Health Survey Data (Includes Cleaning and Export to CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\austi\\Documents\\GitHub\\COMP5360Project\\project_files\\csv_files\\2020 County Health Rankings Data - v1.csv',skiprows=1)\n",
    "df=df[['State','County','Deaths','Years of Potential Life Lost Rate','Average Number of Physically Unhealthy Days','Average Number of Mentally Unhealthy Days','% Smokers','% Adults with Obesity','Food Environment Index','% Physically Inactive','% With Access to Exercise Opportunities','Chlamydia Rate','% Uninsured','# Primary Care Physicians','Primary Care Physicians Rate','Preventable Hospitalization Rate','% Vaccinated','High School Graduation Rate','% Some College','% Unemployed','% Children in Poverty','Income Ratio','% Single-Parent Households','Social Association Rate','Average Daily PM2.5','% Severe Housing Problems','% Long Commute - Drives Alone']]\n",
    "df.set_index('State')\n",
    "df['County'].fillna(0,inplace=True)\n",
    "\n",
    "statelvl=df.loc[df['County']==0]\n",
    "statelvl=statelvl.drop(['County'],axis=1)\n",
    "\n",
    "#Nan pm2.5 values filled in with this source: http://berkeleyearth.lbl.gov/air-quality/local/United_States_of_America/Hawaii\n",
    "statelvl.loc[statelvl['State']=='Alaska','Average Daily PM2.5']=12\n",
    "statelvl.loc[statelvl['State']=='Hawaii','Average Daily PM2.5']=3.9 \n",
    "#statelvl.dtypes\n",
    "statelvl.to_csv(r'C:\\Users\\austi\\Documents\\GitHub\\COMP5360Project\\project_files\\csv_files\\Nation_HealthSurvey_Variables.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Scraping World Health Organization PDF for the Global Health index Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "with pdfplumber.open(r\"C:\\Users\\austi\\Documents\\GitHub\\COMP5360Project\\project_files\\pdf_resources\\world_health_index.pdf\") as pdf:\n",
    "    pages = pdf.pages[17]\n",
    "    table = pages.extract_table()\n",
    "    pages2 = pdf.pages[18]\n",
    "    table2 = pages2.extract_table()\n",
    "    pages3 = pdf.pages[19]\n",
    "    table3 = pages3.extract_table()\n",
    "    pages4 = pdf.pages[20]\n",
    "    table4 = pages4.extract_table()\n",
    "    \n",
    "df = pd.DataFrame(table[1:], columns=table[1])\n",
    "df.head()\n",
    "df=df[['Rank','Member State', 'Index']]\n",
    "\n",
    "data = pd.DataFrame(table2[1:], columns=table2[1])\n",
    "data=data[['55','Albania', '0.774']]\n",
    "data=data.rename(columns={'55':'Rank','Albania':'Member State', '0.774':'Index'})                \n",
    "df=df.append(data,ignore_index=True)\n",
    "\n",
    "data = pd.DataFrame(table3[1:], columns=table3[1])\n",
    "data=data[['117','Uzbekistan', '0.599']]\n",
    "data=data.rename(columns={'117':'Rank','Uzbekistan':'Member State', '0.599':'Index'})                 \n",
    "df=df.append(data,ignore_index=True)\n",
    "\n",
    "data = pd.DataFrame(table4[1:], columns=table4[1])\n",
    "data=data[['178','Chad', '0.303']]\n",
    "data=data.rename(columns={'178':'Rank','Chad':'Member State', '0.303':'Index'})                  \n",
    "df=df.append(data,ignore_index=True)\n",
    "\n",
    "for column in [\"Rank\", \"Member State\", 'Index']:\n",
    "    df[column] = df[column].str.replace(\" \", \"\")\n",
    "    df[column] = df[column].replace('\\n','', regex=True)\n",
    "df=df.dropna()\n",
    "df=df.drop([0])\n",
    "df.set_index('Rank')\n",
    "df['Rank']=df['Rank'].astype(int)\n",
    "df['Index']=df['Index'].astype(float)\n",
    "df['Member State']=df['Member State'].astype(str)\n",
    "df.dtypes\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "    print(df)\n",
    "    \n",
    "df.to_csv(r'C:\\Users\\austi\\Documents\\GitHub\\COMP5360Project\\project_files\\csv_files\\CLEAN_WorldHealthIndex.csv', index=False)\n",
    "\n",
    "import pandas as pd\n",
    "df2 = pd.read_csv('/Users/spenc/OneDrive/Documents/University_of_Utah/2019-2020/DataScience/COMP5360Project/project_files/csv_files/CLEAN_WorldHealthIndex.csv')\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CLEANING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GLOBAL AND NATIONAL: CONFIRMED, DEATHS, RECOVERED (CDR) DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/csv_files/CDRdata.csv\")\n",
    "df\n",
    "\n",
    "df = pd.read_csv(\"/Users/spenc/OneDrive/Documents/University_of_Utah/2019-2020/DataScience/COMP5360Project/project_files/csv_files/CDRdata.csv\")\n",
    "df\n",
    "\n",
    "df.describe()\n",
    "\n",
    "df[\"Confirmed\"] = df[\"Confirmed\"].fillna(0)\n",
    "df[\"Deaths\"] = df[\"Deaths\"].fillna(0)\n",
    "df[\"Recovered\"] = df[\"Recovered\"].fillna(0)\n",
    "df\n",
    "\n",
    "df = df[[\"Country/Region\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\"]]\n",
    "df\n",
    "\n",
    "df[\"Country/Region\"] = df[\"Country/Region\"].replace(\"Mainland China\", \"China\")\n",
    "df\n",
    "\n",
    "#df = df.rename({\"Mod_col\":\"Col_1\",\"B\":\"Col_2\"}, axis='columns')\n",
    "\n",
    "countries = ['US', 'China', 'Italy', 'New Zealand', 'South Korea', 'UK', 'Iran', 'Singapore', 'India', 'Peru']\n",
    "df = df.loc[df['Country/Region'].isin(countries)]\n",
    "df\n",
    "\n",
    "df[\"Confirmed\"] = df[\"Confirmed\"].astype(\"int\")\n",
    "df[\"Deaths\"] = df[\"Deaths\"].astype(\"int\")\n",
    "df[\"Recovered\"] = df[\"Recovered\"].astype(\"int\")\n",
    "df.dtypes\n",
    "\n",
    "df.to_csv('/Users/spenc/OneDrive/Documents/University_of_Utah/2019-2020/DataScience/COMP5360Project/project_files/csv_files/CLEANCDRData.csv', index = False)\n",
    "\n",
    "df.to_csv('/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/csv_files/CLEANCDRData.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## World CDR DATA WITH LATITUDE AND LOGNITUDE (10 COUNTRIES SELECTED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/csv_files/LatLongdata.csv\")\n",
    "df\n",
    "\n",
    "df.describe()\n",
    "\n",
    "df[\"Confirmed\"] = df[\"Confirmed\"].fillna(0)\n",
    "df[\"Deaths\"] = df[\"Deaths\"].fillna(0)\n",
    "df[\"Recovered\"] = df[\"Recovered\"].fillna(0)\n",
    "df\n",
    "\n",
    "df = df[[\"Country/Region\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\", \"Latitude\", \"Longitude\"]]\n",
    "df\n",
    "\n",
    "countries = ['US', 'Mainland China', 'Italy', 'New Zealand', 'South Korea', 'UK', 'Iran', 'Singapore', 'India', 'Peru']\n",
    "df = df.loc[df['Country/Region'].isin(countries)]\n",
    "df\n",
    "\n",
    "df.describe()\n",
    "\n",
    "df.to_csv(r'/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/csv_files/CLEANLatLonData.csv', index = False)\n",
    "\n",
    "df = pd.read_csv(\"/Users/spenc/OneDrive/Documents/University_of_Utah/2019-2020/DataScience/COMP5360Project/project_files/csv_files/CLEANLatLongdata.csv\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Cleaning National CDR data with LAT and LON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/csv_files/USLatLon.csv\")\n",
    "df\n",
    "\n",
    "df.describe()\n",
    "\n",
    "df[\"Confirmed\"] = df[\"Confirmed\"].fillna(0)\n",
    "df[\"Deaths\"] = df[\"Deaths\"].fillna(0)\n",
    "df[\"Recovered\"] = df[\"Recovered\"].fillna(0)\n",
    "df\n",
    "\n",
    "df = df[[\"Country/Region\", \"Last Update\", \"Confirmed\", \"Deaths\", \"Recovered\", \"Latitude\", \"Longitude\"]]\n",
    "df\n",
    "\n",
    "countries = ['US', 'Mainland China', 'Italy', 'New Zealand', 'South Korea', 'UK', 'Iran', 'Singapore', 'India', 'Peru']\n",
    "df = df.loc[df['Country/Region'].isin(countries)]\n",
    "df\n",
    "\n",
    "df.describe()\n",
    "\n",
    "df.to_csv(r'/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/csv_files/CLEANUSLatLon.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Cleaning Global Population Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/csv_files/population_and_density_by_country.csv\")\n",
    "df\n",
    "\n",
    "df = pd.read_csv(\"/Users/spenc/OneDrive/Documents/University_of_Utah/2019-2020/DataScience/COMP5360Project/project_files/csv_files/population_and_density_by_country.csv\")\n",
    "df\n",
    "\n",
    "df = df[[\"name\",\"Rank\", \"pop2019\", \"GrowthRate\", \"area\", \"Density\"]]\n",
    "df\n",
    "\n",
    "countries = ['China','United States', 'Italy', 'New Zealand', 'South Korea', 'United Kingdom', 'Iran', 'Singapore', 'India', 'Peru']\n",
    "df = df.loc[df['name'].isin(countries)]\n",
    "df\n",
    "\n",
    "df['pop2019'] = df['pop2019'].astype('int')\n",
    "df['area'] = df['area'].astype('int')\n",
    "df\n",
    "\n",
    "df.describe()\n",
    "\n",
    "df.to_csv(r'/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/csv_files/CLEANpopulation_and_density_by_country.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Cleaning National Population Data: downloaded from csv file found on world population pg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/markomiholjcic/Documents/GitHub/COMP5360Project/project_files/csv_files/population_and_population_density_USA.csv\")\n",
    "df\n",
    "\n",
    "df.describe()\n",
    "\n",
    "#People per square mile\n",
    "\n",
    "df2 = pd.read_csv('/Users/spenc/OneDrive/Documents/University_of_Utah/2019-2020/DataScience/COMP5360Project/project_files/csv_files/CLEANpopulation_and_population_density_USA.csv')\n",
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Organizing COVID 19 Data by Date \"Time Series\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### EXPLORATORY ANALYSIS: PLOTTING EXISTING DATA OF CONFIRMED CASES (BY COUNTRY [10 COUNTRIES] AND STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CREATING A LOGISTIC REGRESSION MODEL BASED ON KNOWN DATA, CURVE FITTING, AND MATHMATICAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
